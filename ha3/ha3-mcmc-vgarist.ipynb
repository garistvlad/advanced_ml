{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MADE. Advanced ML. Home assignment #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Adventure of the Dancing Men\n",
    "\n",
    "<img src=\"./data/img/dancing_men.png\" width=\"600\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "Реализуйте базовый частотный метод по Шерлоку Холмсy\n",
    "\n",
    "- подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "- возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "- расшифруйте их таким частотным методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt; plt.ion()\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_DATAPATH = \"data/corpora\"\n",
    "WAR_AND_PEACE_RU_FILEPATH = os.path.join(CORPUS_DATAPATH, \"WarAndPeace.txt\")\n",
    "WAR_AND_PEACE_EN_FILEPATH = os.path.join(CORPUS_DATAPATH, \"WarAndPeaceEng.txt\")\n",
    "ANNA_KARENINA_RU_FILEPATH = os.path.join(CORPUS_DATAPATH, \"AnnaKarenina.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(filepath: str) -> str:\n",
    "    with open(filepath, 'r') as f:\n",
    "        text = f.read()\n",
    "        text = text.replace('\\n', ' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str, languare: str = 'ru') -> str:\n",
    "    \"\"\"Process text with following steps:\n",
    "    1. To lower case\n",
    "    2. Take only letters from appropriate languare\n",
    "    3. Replace sequence of subspaces to one\n",
    "    \"\"\"\n",
    "    processed = text.lower()\n",
    "    if languare == \"ru\":\n",
    "        pattern_to_delete = re.compile(\"[^а-яё ]\")\n",
    "    elif languare == \"en\":\n",
    "        pattern_to_delete = re.compile(\"[^a-z ]\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown languale: {languare}\")\n",
    "    processed = re.sub(pattern_to_delete, \" \", processed)\n",
    "    processed = re.sub(r\"\\s+\", \" \", processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2807264e80534f3b81afd95e5eee8003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CORPUS = dict()\n",
    "\n",
    "for text_id, text_filepath, lang in tqdm(zip(\n",
    "    [\"war_and_peace_ru\", \"war_and_peace_en\", \"anna_karenina_ru\"],\n",
    "    [WAR_AND_PEACE_RU_FILEPATH, WAR_AND_PEACE_EN_FILEPATH, ANNA_KARENINA_RU_FILEPATH],\n",
    "    [\"ru\", \"en\", \"ru\"]\n",
    ")):\n",
    "    text_i = read_text(text_filepath)\n",
    "    CORPUS[text_id] = preprocess_text(text_i, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war_and_peace_ru\n",
      " война и мир самый известный роман льва николаевича толстого как никакое другое произведение писател \n",
      "\n",
      "war_and_peace_en\n",
      " the project gutenberg ebook of war and peace by leo tolstoy this ebook is for the use of anyone any \n",
      "\n",
      "anna_karenina_ru\n",
      " анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой вс \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text_id, text_processed in CORPUS.items():\n",
    "    print(text_id)\n",
    "    print(text_processed[:100], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Частоты по корпусам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_letter_frequencies(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate relative frequencies of characters from text\"\"\"\n",
    "    letter_counter = Counter(text)\n",
    "    letter_counter = {i: j / len(text) for i, j in letter_counter.items()}\n",
    "    letter_counter = dict(\n",
    "        sorted(\n",
    "            letter_counter.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "    )\n",
    "    return letter_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Зашифруем и попробуем расшифровать тестовые данные случайной перестановкой символов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alphabet(language: str) -> List[str]:\n",
    "    \"\"\"Generate list of letters for appripriate languare\"\"\"\n",
    "    if language == \"ru\":\n",
    "        alphabet = [chr(i) for i in range(ord('а'), ord('я') + 1)] + ['ё', \" \"]\n",
    "    elif language == \"en\":\n",
    "        alphabet = [chr(i) for i in range(ord('a'), ord('z') + 1)] + [\" \"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown languale: {languare}\")\n",
    "    return alphabet\n",
    "\n",
    "\n",
    "def get_shuffled_encoder(language: str = \"ru\") -> Dict[str, str]:\n",
    "    \"\"\"Provide mapping from original alphabet to shuffled one\"\"\"\n",
    "    mapping = dict()\n",
    "    alphabet = get_alphabet(language)\n",
    "    new_alphabet = alphabet.copy()\n",
    "    random.shuffle(new_alphabet)\n",
    "    return dict(zip(alphabet, new_alphabet))\n",
    "\n",
    "\n",
    "def encode_text(text: str, encoder: Dict[str, str]) -> str:\n",
    "    \"\"\"Encode text based on encoder latters mapping\"\"\"\n",
    "    result = \"\"\n",
    "    for i in text:\n",
    "        result += encoder.get(i, \"?\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_optimal_decoder(encoded_text: str, train_freq: Dict[str, str]) -> Dict[str, str]:\n",
    "    \"\"\"Optimal decoder from frequencies\"\"\"\n",
    "    test_freq = calculate_letter_frequencies(encoded_text)\n",
    "    decoder = dict(zip(test_freq, train_freq))\n",
    "    return decoder\n",
    "\n",
    "\n",
    "def decode_text(\n",
    "    encoded_text: str,\n",
    "    decoder: Dict[str, str],\n",
    "    missing_value: str = \"?\"\n",
    ") -> str:\n",
    "    \"\"\"Decode text using optimal decoder previously calculated\"\"\"\n",
    "    result = \"\"\n",
    "    for i in encoded_text:\n",
    "        result += decoder.get(i, missing_value)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calculate_accuracy(text_true, text_pred):\n",
    "    \"\"\"Accuracy score of exact letters matching\"\"\"\n",
    "    assert len(text_true) == len(text_pred), \"Text lengths should match exactly\"\n",
    "    return sum([i == j for i, j in zip(text_true, text_pred)]) / len(text_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_encoder = get_shuffled_encoder(\"ru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_freq = calculate_letter_frequencies(CORPUS['war_and_peace_ru'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:     война и мир самый известный роман льва николаевича\n",
      "Encoded:   зфч сюзхзлхозвюлщ зхьфмвгсщ зочлюсзуйфюзсхцчуюмфхню\n",
      "Decoded:    война и мир самый известный роман льва николаевича\n",
      "Accuracy on whole text: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Пример из Train dataset-а\n",
    "test_text = CORPUS['war_and_peace_ru']\n",
    "test_text_encoded = encode_text(test_text, random_encoder)\n",
    "optimal_decoder = get_optimal_decoder(test_text_encoded, train_freq)\n",
    "test_text_decoded = decode_text(\n",
    "    test_text_encoded,\n",
    "    optimal_decoder\n",
    ")\n",
    "\n",
    "print_size = 51\n",
    "print(\"Actual:\".ljust(10), test_text[:print_size])\n",
    "print(\"Encoded:\".ljust(10), test_text_encoded[:print_size])\n",
    "print(\"Decoded:\".ljust(10), test_text_decoded[:print_size])\n",
    "print(f\"Accuracy on whole text: {calculate_accuracy(test_text, test_text_decoded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:     анна каренина один из самых знаменитых романов льва толстого\n",
      "Encoded:   зюссюзцюомсхсюзчрхсзхьзвюлщязьсюлмсхгщязочлюсчфзуйфюзгчувгчбч\n",
      "Decoded:    еиие кераиние одни нч семьх чиемаинтьх ромеиов лгве толстоыо\n",
      "Accuracy on whole text: 0.6291\n"
     ]
    }
   ],
   "source": [
    "# Пример из Test dataset-а, где частоты посчитаны на целом тексте:\n",
    "test_text = CORPUS['anna_karenina_ru']\n",
    "test_text_encoded = encode_text(test_text, random_encoder)\n",
    "optimal_decoder = get_optimal_decoder(test_text_encoded, train_freq)\n",
    "test_text_decoded = decode_text(\n",
    "    test_text_encoded,\n",
    "    optimal_decoder\n",
    ")\n",
    "\n",
    "print_size = 61\n",
    "print(\"Actual:\".ljust(10), test_text[:print_size])\n",
    "print(\"Encoded:\".ljust(10), test_text_encoded[:print_size])\n",
    "print(\"Decoded:\".ljust(10), test_text_decoded[:print_size])\n",
    "print(f\"Accuracy on whole text: {calculate_accuracy(test_text, test_text_decoded):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "\n",
    "- подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "- проведите тестирование аналогично п.1, но при помощи биграмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bigram_frequencies(text: str) -> Dict[str, float]:\n",
    "    \"\"\"Calculate relative frequencies of bigrams from text\"\"\"\n",
    "    bigram_counter = Counter()\n",
    "    for i in range(len(text) - 1):\n",
    "        bigram_counter[text[i: i + 2]] += i\n",
    "    \n",
    "    n_bigrams = sum(bigram_counter.values())\n",
    "    bigram_counter = dict(\n",
    "        sorted(\n",
    "            bigram_counter.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "    )\n",
    "    bigram_counter = {i: j / n_bigrams for i, j in bigram_counter.items()}\n",
    "    return bigram_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abc -> ab bc\n",
    "# ab bc -> abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bigram frequencies using War and Peace [RU] as train dataset:\n",
    "train_bigram_freq = calculate_bigram_frequencies(CORPUS['war_and_peace_ru'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_encoded = encode_text(CORPUS['anna_karenina_ru'], random_encoder)\n",
    "test_bigram_freq = calculate_bigram_frequencies(test_text_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('о ', 0.021671493454038303),\n",
       " ('и ', 0.018108026579692883),\n",
       " ('е ', 0.015485657194981196),\n",
       " ('а ', 0.015362732805954401),\n",
       " (' с', 0.015187212825279217),\n",
       " (' п', 0.015011360591923206),\n",
       " (' в', 0.014898685499327182),\n",
       " (' н', 0.014874541819007736),\n",
       " ('то', 0.013590255845312203),\n",
       " (' о', 0.012039298756919049)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_bigram_freq.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('чз', 0.02382762636749498),\n",
       " ('мз', 0.018935873797493535),\n",
       " ('юз', 0.01851984451320598),\n",
       " ('хз', 0.017957561175334535),\n",
       " ('зс', 0.016333824866984408),\n",
       " ('зв', 0.01606188531157267),\n",
       " ('зф', 0.014739839768844788),\n",
       " ('гч', 0.014256806184461339),\n",
       " ('зы', 0.013971276602894347),\n",
       " ('зч', 0.01349492169970542)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test_bigram_freq.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimal bigram decoder based on bigram frequesncies:\n",
    "bigram_decoder = dict()\n",
    "for test_bg, train_bg in zip(test_bigram_freq.keys(), train_bigram_freq.keys()):\n",
    "    if test_bg[0] not in bigram_decoder and train_bg[0] not in bigram_decoder.values():\n",
    "        bigram_decoder.update({test_bg[0]: train_bg[0]})\n",
    "    if test_bg[1] not in bigram_decoder and train_bg[1] not in bigram_decoder.values():\n",
    "        bigram_decoder.update({test_bg[1]: train_bg[1]})\n",
    "\n",
    "# add missing letters:\n",
    "missing_letters = dict(zip(\n",
    "    [i for i in get_alphabet(\"ru\") if i not in bigram_decoder],\n",
    "    [i for i in get_alphabet(\"ru\") if i not in bigram_decoder.values()]\n",
    "))\n",
    "bigram_decoder.update(missing_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:     анна каренина один из самых знаменитых романов льва толстого\n",
      "Encoded:   зюссюзцюомсхсюзчрхсзхьзвюлщязьсюлмсхгщязочлюсчфзуйфюзгчувгчбч\n",
      "Decoded:    ессе йенисасе отас аз пемых зсемисауых номесов льве уолпуого\n",
      "Accuracy on whole text: 0.4765\n"
     ]
    }
   ],
   "source": [
    "# Пример из Test dataset-а, где частоты посчитаны на целом тексте:\n",
    "test_text_decoded = decode_text(\n",
    "    test_text_encoded,\n",
    "    bigram_decoder\n",
    ")\n",
    "\n",
    "print_size = 61\n",
    "print(\"Actual:\".ljust(10), test_text[:print_size])\n",
    "print(\"Encoded:\".ljust(10), test_text_encoded[:print_size])\n",
    "print(\"Decoded:\".ljust(10), test_text_decoded[:print_size])\n",
    "print(f\"Accuracy on whole text: {calculate_accuracy(test_text, test_text_decoded):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Качество ухудшилось... Перепробовал несколько вариантов, как именно считать decoder на основани биграмм. В данном подходе, где просто поочередно перебираются подряд самые популярные биграммы, удалось достигнуть качества лишь __47.65%__. Другие попытки оказались еще менее удачными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.\n",
    "\n",
    "Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "- предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "- реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n",
    "\n",
    "\n",
    "Следующий символ в тексте зависит от предыдущего символа. Значит, рассмотрим текст как цепь Маркова.<br>\n",
    "Применим MCMC-семплирование. На каждой итерации меняем местами пару символов в текущей перестановке, считаем правдоподобие восстановления текста из текущей пререстановки, принимаем новую перестновку с определённой вероятностью. Выберем лучшую попытку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_permutation(alphabet: List[str]) -> np.ndarray:\n",
    "    \"\"\"Generate random permutation from language specific alphabet\"\"\"\n",
    "    return np.random.permutation(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inplace_swap(permutation: np.ndarray) -> Tuple[int, int]:\n",
    "    \"\"\"Swap 2 random charecters from permutation\"\"\"\n",
    "    a, b = np.random.choice(len(permutation), size=2, replace=False)\n",
    "    permutation[a], permutation[b] = permutation[b], permutation[a]\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_permutation(text: str, permutation: np.ndarray, alphabet: List[str] = ru_alphabet) -> str:\n",
    "    \"\"\"Encode text with permutation\"\"\"\n",
    "    return text.translate(\n",
    "        str.maketrans(''.join(alphabet), ''.join(permutation))\n",
    "    )\n",
    "\n",
    "def get_transition_matrix(text: str) -> np.ndarray:\n",
    "    transition_matrix = np.zeros(\n",
    "        (\n",
    "            len(char_to_idx), len(char_to_idx)\n",
    "        )\n",
    "    )\n",
    "    for i in range(len(text) - 1):\n",
    "        transition_matrix[char_to_idx[text[i]], char_to_idx[text[i + 1]]] += 1\n",
    "    transition_matrix = np.clip(transition_matrix, a_min=1, a_max=None)\n",
    "    transition_matrix = (\n",
    "        np.log(transition_matrix).T - np.log(transition_matrix.sum(axis=1))\n",
    "    ).T\n",
    "    return transition_matrix\n",
    "\n",
    "def calculate_log_likelihood(text: str, permutation: np.ndarray, alphabet: List['str']) -> float:\n",
    "    # encode text with new permutation:\n",
    "    text = apply_permutation(text, permutation, alphabet)\n",
    "    # provide calculation:\n",
    "    result = 0\n",
    "    for i in range(len(text) - 1):\n",
    "        result += transition_matrix[\n",
    "            char_to_idx[text[i]], char_to_idx[text[i + 1]]\n",
    "        ]\n",
    "    return result\n",
    "\n",
    "def get_optimal_permutation_mcmc(text: str, alphabet: List[str], n_iter: int) -> np.ndarray:\n",
    "    permutation = generate_permutation(alphabet)\n",
    "    best_permutation = permutation.copy()\n",
    "    log_likelihood = calculate_log_likelihood(text, permutation, alphabet)\n",
    "    log_likelihood_best = log_likelihood\n",
    "    \n",
    "    for i in tqdm(range(n_iter)):\n",
    "        id_a, id_b = make_inplace_swap(permutation)\n",
    "        log_likelihood_i = calculate_log_likelihood(text, permutation, alphabet)\n",
    "        if log_likelihood_i >= log_likelihood:\n",
    "            log_likelihood = log_likelihood_i\n",
    "            if log_likelihood_i > log_likelihood_best:\n",
    "                log_likelihood_best = log_likelihood_i\n",
    "                best_permutation = permutation.copy()\n",
    "        else:\n",
    "            if random.random() < np.exp(log_likelihood_i - log_likelihood):\n",
    "                log_likelihood = log_likelihood_i\n",
    "            else:\n",
    "                permutation[id_a], permutation[id_b] = permutation[id_b], permutation[id_a]\n",
    "    return best_permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'зюссюзцюомсхсюзчрхсзхьзвюлщязьсюлмсхгщязочлюсчфзуйфюзгчувгчбчзсюнхсюмгвёзвгюфем зютчохьлчлзтоюьч зфвмзвнювгухфщмзвмлйхзычячдхзрожбзсюзрожбюзцюдрюёзсмвнювгухфюёзвмлйёзсмвнювгухфюзычзвфчмлжзэгчзцсхбюзчзфмнсщязпмссчвгёязчзуаъфхзчзфмомзчзвмлймзчзнмучфмнмвцчлзрчвгчхсвгфмзумфзгчувгч очлюсзехочцчбчзрщяюсхёзнювгйзымофюёзумфзгчувгч зюссюзцюомсхсюзочлюсзехочцчбчзрщяюсхёзюссюзцюомсхсюзычоюьхуюзвчфомлмссхцчфзфвмрсмфсчвгйазвчрмодюсхёзсмчъщню сюёзвфчъчрюзоювцчфюссчвгйзычфмвгфчфюсхёзжрхфхгмуйсчзвчнмгюухвйзфзэгчлзочлюсмзвзпмуйсчвгйазяжрчдмвгфмссчбчзфьбуёрюзюфгчоюзсюздхьсйзчсзфщвгжыюузьрмвйзцюцзяжрчдсхцзхзлщвухгмуйзхзсюьсюнмсхмзхвцжввгфюзфхрмузсмзфзгчлзнгчъщзсмчвычохлчзоюьомехгйзфчыочвзюзфзгчлзнгчъщзьювгюфхгйзуаъхгйздхьсйзфзъмвнхвумссщязсхцчбрюзсмзхвгчшхлщязфвмязммзыочёфумсхёязфзмзбчрщзчрхсзлювгхгщ зыхвюгмуйзычзфхрхлчлжзбчснюочфзвцюьюузрчвгчмфвцчлжзэгчзфмшйзсмвущяюссюёзэгчзфмшйзымофюёзцгчзжзсювзхьзыхвюгмум злчдмгзычоюфсёгйвёзвзэгхлзюзфзмфочымзцгчзыомрвгюфхгзячгйзнгчзсхъжрйзычрчъсчмзтзлзрчвгчмфвцх '"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example = test_text[:995]\n",
    "test_example_encoded = encode_text(test_example, random_encoder)\n",
    "test_example_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54c8af03a2248dcb967639577655026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(ru_alphabet)}\n",
    "transition_matrix = get_transition_matrix(CORPUS['war_and_peace_ru'])\n",
    "best_permutation_mcmc = get_optimal_permutation_mcmc(test_example_encoded, ru_alphabet, n_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' анна каренина один из самых знаменитых романов льва толстого начинается ставшей афоризмом фразой все счастливые семьи похожи друг на друга каждая несчастливая семья несчастлива по своему это книга о вечных ценностях о любви о вере о семье о человеческом достоинстве лев толстойроман широкого дыхания часть первая лев толстой анна каренина роман широкого дыхания анна каренина поразила современников вседневностью содержания необычайная свобода раскованность повествования удивительно сочетались в этом романе с цельностью художественного взгляда автора на жизнь он выступал здесь как художник и мыслитель и назначение искусства видел не в том чтобы неоспоримо разрешить вопрос а в том чтобы заставить любить жизнь в бесчисленных никогда не истощимых всех ее проявлениях в е годы один маститый писатель по видимому гончаров сказал достоевскому это вещь неслыханная это вещь первая кто у нас из писателей может поравняться с этим а в европе кто представит хоть что нибудь подобное ф м достоевский'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_permutation(test_example_encoded, best_permutation_mcmc, ru_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(\n",
    "    test_example,\n",
    "    apply_permutation(test_example_encoded, best_permutation_mcmc, ru_alphabet)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "Расшифруйте сообщение:\n",
    "\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸ ↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊ ↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒ ↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝← ⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n",
    "\n",
    "Или это (они одинаковые, второй вариант просто на случай проблем с юникодом):\n",
    "\n",
    "დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭ􏰀ႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭ􏰀ႣჵისႼჰႨჲდႩჳჲႨ􏰀ႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨ ႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵ􏰀ႧჂჲდႨ􏰀ႣႩჳჂ􏰀ႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხს დდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩ􏰀ႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains: 29 unique charecters\n"
     ]
    }
   ],
   "source": [
    "secret_message = (\"←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸ \"\n",
    "\"↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊ ↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛\"\n",
    "\"⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒ ↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝← ⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\")\n",
    "\n",
    "secret_message_alphabet = sorted(set(secret_message))\n",
    "print(f\"Contains: {len(secret_message_alphabet)} unique charecters\")\n",
    "\n",
    "# # add some letters\n",
    "# secret_message_alphabet += ['a', 'b', 'c', 'd', 'f']\n",
    "# assert len(secret_message_alphabet) == len(ru_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ойытдкядктстлодибжрхыпиямдтытдюбчлтдибжрхыпиямдлогйлдздц лбебдйббвуоитндгблбжямдыоегбдюжбчтлхлпдйгбжоодкйоебдкя дкйодйсоыхытдюжхктыпибдтдюбызчтлодрхгйтрхыпиямдвхыы дшхдюбйыосиоодчолкожлбодшхсхитодгзжйхдаблндгбио чибдндитчоебдиодбвоухь\n"
     ]
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(ru_alphabet)}\n",
    "transition_matrix = get_transition_matrix(CORPUS['war_and_peace_ru'])\n",
    "\n",
    "alphabet = list(train_freq.keys())[:len(secret_message_alphabet)]\n",
    "secret_message_encoded = encode_text(\n",
    "    secret_message,\n",
    "    encoder=dict(zip(secret_message_alphabet, alphabet))\n",
    ")\n",
    "\n",
    "print(secret_message_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff2425481d34f3aaf9b8d707181f147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_permutation_mcmc = get_optimal_permutation_mcmc(secret_message_encoded, alphabet, n_iter=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'если вы вимите норжальный или почти норжальный текст у зютого соодцения который легко прочитать скорее всего выю все смелали правильно и получите жаксижальный даллю ба послемнее четвертое бамание курса хотя конеючно я ничего не одецаш'"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_permutation(secret_message_encoded, best_permutation_mcmc, alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
